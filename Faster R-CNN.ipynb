{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJWyzxzUbXQS"
   },
   "source": [
    "Model\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBrt1FCeT1C5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "__all__ = [\"create_model\"]\n",
    "\n",
    "\n",
    "def create_model(num_classes, min_size=300, max_size=500, backbone=\"mobile_net\"):\n",
    "    if backbone == \"mobile_net\":\n",
    "        mobile_net = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "        ft_backbone = mobile_net.features\n",
    "        ft_backbone.out_channels = 1280\n",
    "\n",
    "    elif backbone == \"vgg_11\":\n",
    "        vgg_net = torchvision.models.vgg11(pretrained=True)\n",
    "        ft_backbone = vgg_net.features\n",
    "        ft_backbone.out_channels = 512\n",
    "\n",
    "    elif backbone == \"vgg_13\":\n",
    "        vgg_net = torchvision.models.vgg13(pretrained=True)\n",
    "        ft_backbone = vgg_net.features\n",
    "        ft_backbone.out_channels = 512\n",
    "\n",
    "    elif backbone == \"vgg_16\":\n",
    "        vgg_net = torchvision.models.vgg13(pretrained=True)\n",
    "        ft_backbone = vgg_net.features\n",
    "        ft_backbone.out_channels = 512\n",
    "\n",
    "    elif backbone == \"vgg_19\":\n",
    "        vgg_net = torchvision.models.vgg19(pretrained=True)\n",
    "        ft_backbone = vgg_net.features\n",
    "        ft_backbone.out_channels = 512\n",
    "\n",
    "    elif backbone == \"resnet_18\":\n",
    "        resnet_net = torchvision.models.resnet18(pretrained=True)\n",
    "        modules = list(resnet_net.children())[:-1]\n",
    "        ft_backbone = nn.Sequential(*modules)\n",
    "        ft_backbone.out_channels = 512\n",
    "\n",
    "    elif backbone == \"resnet_34\":\n",
    "        resnet_net = torchvision.models.resnet34(pretrained=True)\n",
    "        modules = list(resnet_net.children())[:-1]\n",
    "        ft_backbone = nn.Sequential(*modules)\n",
    "        ft_backbone.out_channels = 512\n",
    "\n",
    "    elif backbone == \"resnet_50\":\n",
    "        resnet_net = torchvision.models.resnet50(pretrained=True)\n",
    "        modules = list(resnet_net.children())[:-1]\n",
    "        ft_backbone = nn.Sequential(*modules)\n",
    "        ft_backbone.out_channels = 2048\n",
    "\n",
    "    elif backbone == \"resnet_101\":\n",
    "        resnet_net = torchvision.models.resnet101(pretrained=True)\n",
    "        modules = list(resnet_net.children())[:-1]\n",
    "        ft_backbone = nn.Sequential(*modules)\n",
    "        ft_backbone.out_channels = 2048\n",
    "\n",
    "    elif backbone == \"resnet_152\":\n",
    "        resnet_net = torchvision.models.resnet152(pretrained=True)\n",
    "        modules = list(resnet_net.children())[:-1]\n",
    "        ft_backbone = nn.Sequential(*modules)\n",
    "        ft_backbone.out_channels = 2048\n",
    "\n",
    "    elif backbone == \"resnext101_32x8d\":\n",
    "        resnet_net = torchvision.models.resnext101_32x8d(pretrained=True)\n",
    "        modules = list(resnet_net.children())[:-1]\n",
    "        ft_backbone = nn.Sequential(*modules)\n",
    "        ft_backbone.out_channels = 2048\n",
    "\n",
    "    else:\n",
    "        print(\"Error Wrong unsupported Backbone\")\n",
    "        return\n",
    "\n",
    "    ft_mean = [0.485, 0.456, 0.406]\n",
    "    ft_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    ft_anchor_generator = AnchorGenerator(\n",
    "        sizes=((32, 64, 128),), aspect_ratios=((0.5, 1.0, 2.0),)\n",
    "    )\n",
    "\n",
    "    ft_roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "        featmap_names=['0','1','3'], output_size=7, sampling_ratio=2\n",
    "    )\n",
    "\n",
    "    ft_model = FasterRCNN(\n",
    "        # min_size=ft_min_size,\n",
    "        # max_size=ft_max_size,\n",
    "        image_mean=ft_mean,\n",
    "        image_std=ft_std,\n",
    "        backbone=ft_backbone,\n",
    "        num_classes=num_classes,\n",
    "        rpn_anchor_generator=ft_anchor_generator,\n",
    "        )\n",
    "\n",
    "    return ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAGOgic2WG9A"
   },
   "source": [
    "Configurations\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hv74zKH-UGt7"
   },
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = \"/content/drive/MyDrive/testing/csv_files/train_labels.csv\"\n",
    "VALIDATION_CSV_PATH = \"/content/drive/MyDrive/testing/csv_files/test_labels.csv\"\n",
    "IMAGE_DIR = \"/content/drive/MyDrive/testing/cards_in_box/images\"\n",
    "TARGET_COL = \"class\"\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "VALID_BATCH_SIZE = 1\n",
    "TRAIN_WORKERS = 1\n",
    "LEARNING_RATE = 2e-4\n",
    "EPOCHS = 10\n",
    "NUM_CLASSES = 3\n",
    "DETECTION_THRESHOLD = 0.6\n",
    "\n",
    "BACKBONE = \"mobile_net\"\n",
    "MODEL_SAVE_PATH = \"/content/drive/MyDrive/testing/model/faster_rcnn_version1_{}.pt\".format(BACKBONE)\n",
    "\n",
    "OUTPUT_PATH = \"/content/drive/MyDrive/testing/cards_in_box/output\"\n",
    "\n",
    "PREDICT_IMAGE = '/content/predicting_images/GOPR1561.JPG'\n",
    "SAVE_IMAGE = '/content/saving_images'\n",
    "SAVE_DIR = \"/content/drive/MyDrive/testing/cards_in_box/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vm_Q9RCAWFaw"
   },
   "source": [
    "Dataset\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPf7NxWmUfBS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "__all__ = [\"detection_dataset\"]\n",
    "\n",
    "\n",
    "class detection_dataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, target, transforms=None, train=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = dataframe[\"image_id\"].unique()\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = dataframe\n",
    "        self.train = train\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "        image_src = os.path.join(self.image_dir, str(image_id))\n",
    "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        if self.transforms is not None:  # Apply transformation\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        if self.train is False:  # For test data\n",
    "            return image, image_id\n",
    "\n",
    "        # Else for train and validation data\n",
    "        records = self.df[self.df[\"image_id\"] == image_id]\n",
    "        boxes = records[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "\n",
    "        # For has_mask\n",
    "        labels = records[self.target].values\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        # print(labels)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = torch.tensor([index])\n",
    "        target[\"area\"] = area\n",
    "\n",
    "        return image, target, image_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QE3qLCbWCAw"
   },
   "source": [
    "Engine training functions\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Km5hIBSUfiy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "__all__ = [\"train_fn\", \"eval_fn\"]\n",
    "\n",
    "\n",
    "def train_fn(train_dataloader, detector, optimizer, device, scheduler=None):\n",
    "    detector.train()\n",
    "    for images, targets, image_ids in train_dataloader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = detector(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "return loss_value\n",
    "\n",
    "\n",
    "def eval_fn(val_dataloader, detector, device, detection_threshold=0.45):\n",
    "    results = []\n",
    "    detector.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_ids in val_dataloader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "\n",
    "            model_time = time.time()\n",
    "            outputs = detector(images)\n",
    "            model_time = time.time() - model_time\n",
    "\n",
    "            for i, image in enumerate(images):\n",
    "                boxes = (\n",
    "                    outputs[i][\"boxes\"].data.cpu().numpy()\n",
    "                )  # Format of the output's box is [Xmin,Ymin,Xmax,Ymax]\n",
    "                scores = outputs[i][\"scores\"].data.cpu().numpy()\n",
    "                labels = outputs[i][\"labels\"].data.cpu().numpy()\n",
    "                image_id = image_ids[i]\n",
    "                result = {  # Store the image id and boxes and scores in result dict.\n",
    "                    \"image_id\": image_id,\n",
    "                    \"boxes\": boxes,\n",
    "                    \"scores\": scores,\n",
    "                    \"labels\": labels,\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHCqmqHVV_hf"
   },
   "source": [
    "Utils\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlfDwV_bUf9f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from collections import defaultdict, deque\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributed as dist\n",
    "import random\n",
    "import errno\n",
    "import os\n",
    "\n",
    "# My utils\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def show_loader_images(images, targets, device):\n",
    "    images = list(image for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    boxes = targets[4][\"boxes\"].cpu().numpy().astype(np.int32)\n",
    "    # Torch takes channels first format we need to change to channels last\n",
    "    sample = images[4].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(sample, (box[0], box[1]), (box[2], box[3]), (220, 0, 0), 3)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(sample)\n",
    "\n",
    "\n",
    "def random_show_images(root_dir, df, no_images=5, fmt=\".jpg\"):\n",
    "\n",
    "    random_image_l = random.sample(range(0, 500), no_images)\n",
    "    # random_image_l = [1, 2, 3]\n",
    "\n",
    "    for image_id in random_image_l:\n",
    "\n",
    "        img_path = os.path.join(root_dir, str(image_id))\n",
    "        img_path += fmt\n",
    "        # print(img_path)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        print(\"image no {}\".format(image_id))\n",
    "        # plt.imshow(image)\n",
    "        plt.figure()\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        for i, image_name in enumerate(df[\"image_id\"]):\n",
    "            # print(image_name)\n",
    "            if str(image_name) == str(image_id):\n",
    "                # print(\"yes\")\n",
    "                xtl = int(df[\"xmin\"].iloc[i])\n",
    "                ytl = int(df[\"ymin\"].iloc[i])\n",
    "                xbr = int(df[\"xmax\"].iloc[i])\n",
    "                ybr = int(df[\"ymax\"].iloc[i])\n",
    "                # print(xtl, ytl, xbr, ybr)\n",
    "                has_helmet = str(df[\"has_helmet\"].iloc[i]) + \" helmet\"\n",
    "                has_mask = str(df[\"has_mask\"].iloc[i]) + \" mask\"\n",
    "                cv2.rectangle(image, (xtl, ytl), (xbr, ybr), color=(0, 255, 0))\n",
    "                cv2.putText(\n",
    "                    image,\n",
    "                    has_helmet,\n",
    "                    (xtl, ytl),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (36, 255, 12),\n",
    "                    2,\n",
    "                )\n",
    "                cv2.putText(\n",
    "                    image,\n",
    "                    has_mask,\n",
    "                    (xbr, ybr),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (36, 255, 12),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "        plt.imshow(image)\n",
    "\n",
    "\n",
    "# Let's get distrigbution stats for our labeled data\n",
    "def get_distribution_column(df, column):\n",
    "    print(df[column].value_counts())\n",
    "    df[column].value_counts().sort_values().plot(kind=\"bar\")\n",
    "\n",
    "class SmoothedValue(object):\n",
    "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
    "    window or the global series average.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size=20, fmt=None):\n",
    "        if fmt is None:\n",
    "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
    "        self.deque = deque(maxlen=window_size)\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.deque.append(value)\n",
    "        self.count += n\n",
    "        self.total += value * n\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        \"\"\"\n",
    "        Warning: does not synchronize the deque!\n",
    "        \"\"\"\n",
    "        if not is_dist_avail_and_initialized():\n",
    "            return\n",
    "        t = torch.tensor([self.count, self.total], dtype=torch.float64, device=\"cuda\")\n",
    "        dist.barrier()\n",
    "        dist.all_reduce(t)\n",
    "        t = t.tolist()\n",
    "        self.count = int(t[0])\n",
    "        self.total = t[1]\n",
    "\n",
    "    @property\n",
    "    def median(self):\n",
    "        d = torch.tensor(list(self.deque))\n",
    "        return d.median().item()\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
    "        return d.mean().item()\n",
    "\n",
    "    @property\n",
    "    def global_avg(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    @property\n",
    "    def max(self):\n",
    "        return max(self.deque)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.deque[-1]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fmt.format(\n",
    "            median=self.median,\n",
    "            avg=self.avg,\n",
    "            global_avg=self.global_avg,\n",
    "            max=self.max,\n",
    "            value=self.value,\n",
    "        )\n",
    "\n",
    "\n",
    "def all_gather(data):\n",
    "    \"\"\"\n",
    "    Run all_gather on arbitrary picklable data (not necessarily tensors)\n",
    "    Args:\n",
    "        data: any picklable object\n",
    "    Returns:\n",
    "        list[data]: list of data gathered from each rank\n",
    "    \"\"\"\n",
    "    world_size = get_world_size()\n",
    "    if world_size == 1:\n",
    "        return [data]\n",
    "\n",
    "    # serialized to a Tensor\n",
    "    buffer = pickle.dumps(data)\n",
    "    storage = torch.ByteStorage.from_buffer(buffer)\n",
    "    tensor = torch.ByteTensor(storage).to(\"cuda\")\n",
    "\n",
    "    # obtain Tensor size of each rank\n",
    "    local_size = torch.tensor([tensor.numel()], device=\"cuda\")\n",
    "    size_list = [torch.tensor([0], device=\"cuda\") for _ in range(world_size)]\n",
    "    dist.all_gather(size_list, local_size)\n",
    "    size_list = [int(size.item()) for size in size_list]\n",
    "    max_size = max(size_list)\n",
    "\n",
    "    tensor_list = []\n",
    "    for _ in size_list:\n",
    "        tensor_list.append(torch.empty((max_size,), dtype=torch.uint8, device=\"cuda\"))\n",
    "    if local_size != max_size:\n",
    "        padding = torch.empty(\n",
    "            size=(max_size - local_size,), dtype=torch.uint8, device=\"cuda\"\n",
    "        )\n",
    "        tensor = torch.cat((tensor, padding), dim=0)\n",
    "    dist.all_gather(tensor_list, tensor)\n",
    "\n",
    "    data_list = []\n",
    "    for size, tensor in zip(size_list, tensor_list):\n",
    "        buffer = tensor.cpu().numpy().tobytes()[:size]\n",
    "        data_list.append(pickle.loads(buffer))\n",
    "\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def reduce_dict(input_dict, average=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_dict (dict): all the values will be reduced\n",
    "        average (bool): whether to do average or sum\n",
    "    Reduce the values in the dictionary from all processes so that all processes\n",
    "    have the averaged results. Returns a dict with the same fields as\n",
    "    input_dict, after reduction.\n",
    "    \"\"\"\n",
    "    world_size = get_world_size()\n",
    "    if world_size < 2:\n",
    "        return input_dict\n",
    "    with torch.no_grad():\n",
    "        names = []\n",
    "        values = []\n",
    "        # sort the keys so that they are consistent across processes\n",
    "        for k in sorted(input_dict.keys()):\n",
    "            names.append(k)\n",
    "            values.append(input_dict[k])\n",
    "        values = torch.stack(values, dim=0)\n",
    "        dist.all_reduce(values)\n",
    "        if average:\n",
    "            values /= world_size\n",
    "        reduced_dict = {k: v for k, v in zip(names, values)}\n",
    "    return reduced_dict\n",
    "\n",
    "\n",
    "class MetricLogger(object):\n",
    "    def __init__(self, delimiter=\"\\t\"):\n",
    "        self.meters = defaultdict(SmoothedValue)\n",
    "        self.delimiter = delimiter\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = v.item()\n",
    "            assert isinstance(v, (float, int))\n",
    "            self.meters[k].update(v)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.meters:\n",
    "            return self.meters[attr]\n",
    "        if attr in self.__dict__:\n",
    "            return self.__dict__[attr]\n",
    "        raise AttributeError(\n",
    "            \"'{}' object has no attribute '{}'\".format(type(self).__name__, attr)\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        loss_str = []\n",
    "        for name, meter in self.meters.items():\n",
    "            loss_str.append(\"{}: {}\".format(name, str(meter)))\n",
    "        return self.delimiter.join(loss_str)\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        for meter in self.meters.values():\n",
    "            meter.synchronize_between_processes()\n",
    "\n",
    "    def add_meter(self, name, meter):\n",
    "        self.meters[name] = meter\n",
    "\n",
    "    def log_every(self, iterable, print_freq, header=None):\n",
    "        i = 0\n",
    "        if not header:\n",
    "            header = \"\"\n",
    "        start_time = time.time()\n",
    "        end = time.time()\n",
    "        iter_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
    "        data_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
    "        space_fmt = \":\" + str(len(str(len(iterable)))) + \"d\"\n",
    "        log_msg = self.delimiter.join(\n",
    "            [\n",
    "                header,\n",
    "                \"[{0\" + space_fmt + \"}/{1}]\",\n",
    "                \"eta: {eta}\",\n",
    "                \"{meters}\",\n",
    "                \"time: {time}\",\n",
    "                \"data: {data}\",\n",
    "                \"max mem: {memory:.0f}\",\n",
    "            ]\n",
    "        )\n",
    "        MB = 1024.0 * 1024.0\n",
    "        for obj in iterable:\n",
    "            data_time.update(time.time() - end)\n",
    "            yield obj\n",
    "            iter_time.update(time.time() - end)\n",
    "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
    "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
    "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "                print(\n",
    "                    log_msg.format(\n",
    "                        i,\n",
    "                        len(iterable),\n",
    "                        eta=eta_string,\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time),\n",
    "                        data=str(data_time),\n",
    "                        memory=torch.cuda.max_memory_allocated() / MB,\n",
    "                    )\n",
    "                )\n",
    "            i += 1\n",
    "            end = time.time()\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print(\n",
    "            \"{} Total time: {} ({:.4f} s / it)\".format(\n",
    "                header, total_time_str, total_time / len(iterable)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
    "    def f(x):\n",
    "        if x >= warmup_iters:\n",
    "            return 1\n",
    "        alpha = float(x) / warmup_iters\n",
    "        return warmup_factor * (1 - alpha) + alpha\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "\n",
    "def setup_for_distributed(is_master):\n",
    "    \"\"\"\n",
    "    This function disables printing when not in master process\n",
    "    \"\"\"\n",
    "    import builtins as __builtin__\n",
    "\n",
    "    builtin_print = __builtin__.print\n",
    "\n",
    "    def print(*args, **kwargs):\n",
    "        force = kwargs.pop(\"force\", False)\n",
    "        if is_master or force:\n",
    "            builtin_print(*args, **kwargs)\n",
    "\n",
    "    __builtin__.print = print\n",
    "\n",
    "\n",
    "def is_dist_avail_and_initialized():\n",
    "    if not dist.is_available():\n",
    "        return False\n",
    "    if not dist.is_initialized():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_world_size():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 1\n",
    "    return dist.get_world_size()\n",
    "\n",
    "\n",
    "def get_rank():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 0\n",
    "    return dist.get_rank()\n",
    "\n",
    "\n",
    "def is_main_process():\n",
    "    return get_rank() == 0\n",
    "\n",
    "\n",
    "def save_on_master(*args, **kwargs):\n",
    "    if is_main_process():\n",
    "        torch.save(*args, **kwargs)\n",
    "\n",
    "\n",
    "def init_distributed_mode(args):\n",
    "    if \"RANK\" in os.environ and \"WORLD_SIZE\" in os.environ:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "        args.gpu = int(os.environ[\"LOCAL_RANK\"])\n",
    "    elif \"SLURM_PROCID\" in os.environ:\n",
    "        args.rank = int(os.environ[\"SLURM_PROCID\"])\n",
    "        args.gpu = args.rank % torch.cuda.device_count()\n",
    "    else:\n",
    "        print(\"Not using distributed mode\")\n",
    "        args.distributed = False\n",
    "        return\n",
    "\n",
    "    args.distributed = True\n",
    "\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    args.dist_backend = \"nccl\"\n",
    "    print(\n",
    "        \"| distributed init (rank {}): {}\".format(args.rank, args.dist_url), flush=True\n",
    "    )\n",
    "    torch.distributed.init_process_group(\n",
    "        backend=args.dist_backend,\n",
    "        init_method=args.dist_url,\n",
    "        world_size=args.world_size,\n",
    "        rank=args.rank,\n",
    "    )\n",
    "    torch.distributed.barrier()\n",
    "    setup_for_distributed(args.rank == 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woOVtkusm19J"
   },
   "source": [
    "Train\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhMhyEruWOOc"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from torchvision import transforms as T\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "\n",
    "train_loss= []\n",
    "\n",
    "def run():\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    valid_df = pd.read_csv(VALIDATION_CSV_PATH)\n",
    "\n",
    "    train_df=train_df[['filename','xmin','ymin','xmax','ymax','class']]\n",
    "    train_df.columns=['image_id','xmin','ymin','xmax','ymax','class']\n",
    "    train_df['class'] = train_df['class'].map({'green-card': 1, 'yellow-card' : 2 })\n",
    "\n",
    "\n",
    "\n",
    "    valid_df=valid_df[['filename','xmin','ymin','xmax','ymax','class']]\n",
    "    valid_df.columns=['image_id','xmin','ymin','xmax','ymax','class']\n",
    "    valid_df['class'] = valid_df['class'].map({'green-card': 1, 'yellow-card' : 2 })\n",
    "\n",
    "    \n",
    "    train_dataset =detection_dataset(\n",
    "        train_df,\n",
    "        IMAGE_DIR,\n",
    "        target=TARGET_COL,\n",
    "        train=True,\n",
    "        transforms=T.Compose([T.ToTensor()]),\n",
    "    )\n",
    "\n",
    "    valid_dataset = detection_dataset(\n",
    "        valid_df,\n",
    "        IMAGE_DIR,\n",
    "        target=TARGET_COL,\n",
    "        train=True,\n",
    "        transforms=T.Compose([T.ToTensor()]),\n",
    "    )\n",
    "\n",
    "    # print(train_dataset)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    print(\"Data Loaders created\")\n",
    "\n",
    "    detector = create_model(NUM_CLASSES, backbone=BACKBONE)\n",
    "    params = [p for p in detector.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(params, lr=LEARNING_RATE)\n",
    "    # lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "    detector.to(device)\n",
    "\n",
    "    print(\"Model loaded to device\")\n",
    "\n",
    "    print(\"---------------- Training Started --------------\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "      t = time.time()\n",
    "      loss_value = train_fn(train_dataloader, detector, optimizer, device)\n",
    "      t = time.time()-t\n",
    "      min = int(t/60)\n",
    "      print(\"epoch = {}, time_needed = {} mins {:.2f} secs ,Training_loss = {}\".format(epoch+1,min ,t - min * 60, loss_value))\n",
    "      train_loss.append(loss_value)  \n",
    "      # Set the threshold as per needs\n",
    "      results = eval_fn(\n",
    "      valid_dataloader,\n",
    "      detector,\n",
    "      device,\n",
    "      detection_threshold=DETECTION_THRESHOLD,\n",
    "      )\n",
    "      # Pretty printing the results\n",
    "      # pprint(results)\n",
    "    torch.save(detector.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(\"-\" * 25)\n",
    "    print(\"Model Trained and Saved to Disk\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1tIrRYXGVjx"
   },
   "source": [
    "Inference\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDTXT8pCrXBb"
   },
   "outputs": [],
   "source": [
    "# This script does only inference from the loaded model\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "!rm -r /content/predicting_images/.ipynb_checkpoints\n",
    "__all__ = [\n",
    "    \"load_model\",\n",
    "    \"load_image_tensor\",\n",
    "    \"get_prediction\",\n",
    "    \"draw_box\",\n",
    "    \"load_image_to_plot\",\n",
    "    \"save_prediction\",\n",
    "    \"get_folder_results\",\n",
    "]\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    detector = create_model(num_classes=NUM_CLASSES)\n",
    "    detector.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "    detector.eval()\n",
    "    detector.to(device)\n",
    "    return detector\n",
    "\n",
    "\n",
    "# Load the detector for inference\n",
    "\n",
    "\n",
    "def load_image_tensor(image_path, device):\n",
    "    image_tensor = T.ToTensor()(Image.open(image_path))\n",
    "    input_images = [image_tensor.to(device)]\n",
    "    return input_images\n",
    "\n",
    "\n",
    "def get_prediction(detector, images):\n",
    "    with torch.no_grad():\n",
    "        prediction = detector(images)\n",
    "        return prediction\n",
    "\n",
    "\n",
    "def draw_box(image, box, label_id, score):\n",
    "    xmin = int(box[0])\n",
    "    ymin = int(box[1])\n",
    "    xmax = int(box[2])\n",
    "    ymax = int(box[3])\n",
    "    # Some hard coding for label\n",
    "    if label_id == 1:\n",
    "        label = \"Green-Card\" + \": {0:.2f}\" .format(100 * score) + \" %\"\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color=(0, 255, 0),thickness = 5)\n",
    "        cv2.putText(image, label, (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0),5)\n",
    "\n",
    "    elif label_id == 2:\n",
    "        label = \"Yellow-Card\"+ \": {0:.2f}\" .format(100 * score) + \" %\"\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color=(0, 255, 255),thickness = 5)\n",
    "        cv2.putText(image, label, (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,255),7)\n",
    "\n",
    "    elif label_id == 3:\n",
    "        label = \"invisible\"\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color=(0, 0, 255))\n",
    "    elif label_id == 4:\n",
    "        label = \"wrong\"\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color=(0, 0, 255))\n",
    "\n",
    "    # cv2.putText(image, label, (xmax, ymax), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12),5)\n",
    "\n",
    "\n",
    "def load_image_to_plot(image_dir):\n",
    "    image = cv2.imread(image_dir, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "\n",
    "def save_prediction(prediction, image_name, image):\n",
    "    for pred in prediction:\n",
    "        boxes = pred[\"boxes\"].data.cpu().numpy()\n",
    "        labels = pred[\"labels\"].data.cpu().numpy()\n",
    "        scores = pred[\"scores\"].data.cpu().numpy()\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if scores[i] >0.90: #DETECTION_THRESHOLD:\n",
    "            box_draw = boxes[i]\n",
    "            label_draw = labels[i]  \n",
    "            score = scores[i]\n",
    "            draw_box(image, box_draw, label_draw, score)\n",
    "    cv2_imshow(image)\n",
    "    #cv2.imwrite(image_name, image)\n",
    "\n",
    "\n",
    "def get_folder_results(detector, image_dir, device):\n",
    "    for image in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, image)\n",
    "        input_images = load_image_tensor(image_path, device)\n",
    "        prediction = get_prediction(detector, input_images)\n",
    "        print(prediction)\n",
    "        image_loaded = load_image_to_plot(image_path)\n",
    "        save_path = os.path.join(SAVE_DIR, image)\n",
    "        save_prediction(prediction, save_path, image_loaded)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   detector = load_model()\n",
    "   print(\"---------- Model succesfully loaded -------- \")\n",
    "   image_dir = '/content/predicting_images'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Faster_rcnn_modified_topresent_ipnyb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
